{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# 1. Start Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[4]\") \\\n",
    "    .appName(\"hdfs_test\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.task.cpus\", \"4\") \\\n",
    "    .config(\"spark.rapids.sql.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.execution.arrow.enabled\", \"true\") \\\n",
    "    .config(\"spark.rapids.memory.gpu.pool.size\", \"6G\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"16g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------+------------------+--------------------+-----+--------+------+------------+------------+-----------+--------+------------+----------------+--------------------+--------+\n",
      "|              artist|               song|emotion|          variance|               Genre|Tempo|Loudness|Energy|Danceability|Positiveness|Speechiness|Liveness|Acousticness|Instrumentalness|     embedded_vector|faiss_id|\n",
      "+--------------------+-------------------+-------+------------------+--------------------+-----+--------+------+------------+------------+-----------+--------+------------+----------------+--------------------+--------+\n",
      "|  (Alla Pugacheva...|Позови меня P.I.M.P|  anger|0.8335142456515902|Unknown,Unknown,U...|  175|   -7.15|    91|          42|          32|          8|      38|           0|              84|[-0.023154184, 0....|       0|\n",
      "|         (Ani Lorak)|         Shady Lady|    joy|0.8335142456515902|Unknown,Unknown,U...|  128|   -13.0|    70|          71|          77|          5|       7|           5|               0|[-0.05586293, 0.0...|       1|\n",
      "|        (Dima Bilan)|            Believe|    joy|0.8335142456515902|Unknown,Unknown,U...|  134|   -6.72|    73|          55|          24|          5|      22|           5|               0|[-0.031063985, 0....|       2|\n",
      "|   (Elena Tsagrinou)|          El Diablo|   love|0.8335142456515902|Unknown,Unknown,U...|  114|   -7.78|    66|          66|          62|         13|      84|           0|               0|[-0.09246308, 0.0...|       3|\n",
      "|        (Eri Sasaki)|    Gate Of Steiner|sadness|0.8335142456515902|Unknown,Unknown,U...|  148|   -6.44|    61|          41|          37|          4|      14|          20|               0|[-0.008496808, 0....|       4|\n",
      "|         (Ivan Dorn)|             Afrika|   love|0.8335142456515902|Unknown,Unknown,U...|  128|    -5.8|    94|          63|          35|          4|      18|           0|              28|[-0.09156948, 0.0...|       5|\n",
      "|         (Ivan Dorn)|            Collaba|    joy|0.8335142456515902|Unknown,Unknown,U...|  152|   -9.57|    88|          47|          13|         27|       6|           8|               5|[-0.040962376, 0....|       6|\n",
      "|         (Ivan Dorn)|            Beverly|    joy|0.8335142456515902|Unknown,Unknown,U...|  113|   -6.46|    77|          73|          68|          5|      22|           0|               5|[-0.025499877, 0....|       7|\n",
      "|      (Jenia Lubich)|       Russian Girl|  anger|0.8335142456515902|Unknown,Unknown,U...|  155|   -8.34|    48|          69|          35|          3|      10|          74|               0|[-0.036486566, 0....|       8|\n",
      "|       (Olga Buzova)|  Not Enough For Me|    joy|0.8335142456515902|Unknown,Unknown,U...|  117|   -5.85|    62|          75|          54|         10|      14|          37|               0|[-0.014549955, 0....|       9|\n",
      "+--------------------+-------------------+-------+------------------+--------------------+-----+--------+------+------------+------------+-----------+--------+------------+----------------+--------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+------------+\n",
      "| book_id|             user_id|text_embedded_vector|    faiss_id|\n",
      "+--------+--------------------+--------------------+------------+\n",
      "|23341863|81ec8d766fc3a5ebd...|[0.036919385, -0....|523986010112|\n",
      "|17315867|81ec8d766fc3a5ebd...|[-0.07486253, 0.0...|523986010113|\n",
      "|18165974|81ec8d766fc3a5ebd...|[-0.044150714, -0...|523986010114|\n",
      "|17345242|81ec8d766fc3a5ebd...|[-0.019383084, 0....|523986010115|\n",
      "|15838920|81ec8d766fc3a5ebd...|[0.06310062, -0.0...|523986010116|\n",
      "| 7940988|81ec8d766fc3a5ebd...|[-0.036082026, 0....|523986010117|\n",
      "| 1162543|81ec8d766fc3a5ebd...|[0.022156745, -0....|523986010118|\n",
      "|10382150|81ec8d766fc3a5ebd...|[0.014546832, -0....|523986010119|\n",
      "|  818056|81ec8d766fc3a5ebd...|[-0.067639105, -4...|523986010120|\n",
      "|15790895|81ec8d766fc3a5ebd...|[-0.016151592, -0...|523986010121|\n",
      "+--------+--------------------+--------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "hdfs_path = \"hdfs://localhost:9009/\"\n",
    "book_reviews = spark.read.parquet(f\"{hdfs_path}golden/sampled_review_info_embedded\")\n",
    "songs = spark.read.parquet(f\"{hdfs_path}golden/song_info_embedded\")\n",
    "songs.show(10)\n",
    "book_reviews.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import os\n",
    "h_path = os.path.expanduser(\"~/silver_layer/\")\n",
    "song_index = faiss.read_index(f\"{h_path}faiss_song_index.index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/06 17:15:04 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# faiss_id -> song_id\n",
    "song_faiss_map = songs.select(\"faiss_id\", \"song\").rdd.collectAsMap()\n",
    "\n",
    "# take embeddings and info from sampled reviews\n",
    "review_rows = book_reviews.select(\"user_id\", \"book_id\", \"text_embedded_vector\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "batch_size = 10000\n",
    "\n",
    "for i in range(0, len(review_rows), batch_size):\n",
    "    batch = review_rows[i:i+batch_size]\n",
    "    \n",
    "    user_ids = [row[\"user_id\"] for row in batch]\n",
    "    book_ids = [row[\"book_id\"] for row in batch]\n",
    "\n",
    "    vectors = np.array([row[\"text_embedded_vector\"] for row in batch], dtype=np.float32)\n",
    "    \n",
    "    vectors /= np.linalg.norm(vectors, axis=1, keepdims=True)  # normalize tuta\n",
    "    \n",
    "    D, I = song_index.search(vectors, 1)\n",
    "    \n",
    "    for j in range(len(batch)):\n",
    "        matched_faiss_id = I[j][0]\n",
    "        matched_song_id = song_faiss_map.get(matched_faiss_id)\n",
    "        if matched_song_id:\n",
    "            results.append((user_ids[j], book_ids[j], matched_song_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+--------+---------------------------------------------+\n",
      "|user_id                         |book_id |song_id                                      |\n",
      "+--------------------------------+--------+---------------------------------------------+\n",
      "|81ec8d766fc3a5ebdc900d7d89f93ab6|18165974|Set in Stone                                 |\n",
      "|81ec8d766fc3a5ebdc900d7d89f93ab6|17345242|Tired                                        |\n",
      "|81ec8d766fc3a5ebdc900d7d89f93ab6|15838920|323 Go Crazy                                 |\n",
      "|81ec8d766fc3a5ebdc900d7d89f93ab6|7940988 |Just Friends                                 |\n",
      "|81ec8d766fc3a5ebdc900d7d89f93ab6|818056  |Figure It Out                                |\n",
      "|81ec8d766fc3a5ebdc900d7d89f93ab6|9998705 |Finally Home                                 |\n",
      "|81ec8d766fc3a5ebdc900d7d89f93ab6|104378  |Speakeasy                                    |\n",
      "|81ec8d766fc3a5ebdc900d7d89f93ab6|1480129 |Blue Trail Of Sorrow                         |\n",
      "|6464c2c43af3e8f6e613ceb6cd677fbd|5948908 |Close to Me                                  |\n",
      "|6464c2c43af3e8f6e613ceb6cd677fbd|9551699 |Bikeage                                      |\n",
      "|f118251ce3e1189aed55bb2351651bcc|34189556|Vincent                                      |\n",
      "|f118251ce3e1189aed55bb2351651bcc|31450910|Speakeasy                                    |\n",
      "|f118251ce3e1189aed55bb2351651bcc|30027408|5 Star Rockstar Remix                        |\n",
      "|f118251ce3e1189aed55bb2351651bcc|30199334|Stripped Raped and Strangled                 |\n",
      "|f118251ce3e1189aed55bb2351651bcc|29519514|BLACKPINK - Pretty Savage -JP Ver.- Romanized|\n",
      "|f118251ce3e1189aed55bb2351651bcc|23272028|Figure It Out                                |\n",
      "|f118251ce3e1189aed55bb2351651bcc|29939230|Figure It Out                                |\n",
      "|f118251ce3e1189aed55bb2351651bcc|25733660|Golden                                       |\n",
      "|f118251ce3e1189aed55bb2351651bcc|27276357|Take Time To Know Her                        |\n",
      "|f118251ce3e1189aed55bb2351651bcc|28818314|Lightning                                    |\n",
      "+--------------------------------+--------+---------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# result DataFrame\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", StringType(), True),\n",
    "    StructField(\"book_id\", StringType(), True),\n",
    "    StructField(\"song_id\", StringType(), True)\n",
    "])\n",
    "\n",
    "matched_df = spark.createDataFrame(results, schema)\n",
    "matched_df.count()\n",
    "matched_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "matched_df.write.mode(\"overwrite\").parquet(f\"{hdfs_path}golden/matched_user_book_song.parquet\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
